<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<title>daniela massiceti // flipdial</title>

<link href="{{url_for('static', filename='main.css')}}" rel="stylesheet" type="text/css" media="screen"/>
<link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='twitter-bootstrap.css')}}" />
<link rel="shortcut icon" href="{{ url_for('static', filename='tabby.ico')}}" >
<link rel="icon" href="{{ url_for('static', filename='tabby.ico')}}">

<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Comfortaa" />

<meta name="keywords" content="daniela massiceti, university of oxford, phd student, phil torr, torr vision group, computer vision, oxford">
<meta name="description" content="daniela massiceti // computer vision PhD student" />
<meta name="p:domain_verify" content="15f149f4e12ce0bf04ad541a6e0d8a62"/>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-49520497-2', 'auto');
  ga('send', 'pageview');
</script>

{% if scroll %}
<script> document.location.hash = '#' + '{{ scroll }}'; </script>
{% endif %}
</head>

<body>
<div id="wrapper">
	<header id="top">
    <a href="http://za.linkedin.com/pub/daniela-massiceti/66/422/425" target=_blank><img id="linkedin" src="{{ url_for('static', filename='socialmediaicons/linkedin.png')}}" width="30" height="30" title="linkedin" alt="linkedin"/></a>
    <a href="mailto:daniela@robots.ox.ac.uk" target="_top"><img id="mail" src="{{ url_for('static', filename='socialmediaicons/mail_newcolour.png')}}" width="30" height="30" title="mail: daniela@robots.ox.ac.uk" alt="mail"/></a>
    <a href="https://www.twitter.com/DanniMassi/" target=_blank><img id="twitter" src="{{ url_for('static', filename='socialmediaicons/twitter.png')}}" width="30" height="30" title="twitter: @dannimassi" alt="twitter"/></a>
  </header>
   
  <div id="headerimg">
    <a href="{{ url_for('home') }}">
      <div class = "h">Daniela Massiceti</div>
    </a>
	<div class ="subh">D.Phil Student in Computer Vision, University of Oxford </div>
  </div>
 	<hr id="tophr"> 
	    <nav class="navigationbar">
    		<ul>
          <li><a class="normal" href="{{ url_for('home') }}" id=" ">home</a></li>
          <li><a class="normal" href="{{ url_for('about') }}" id=" ">about</a></li>
          <li><a class="normal" href="{{ url_for('research') }}" id=" ">research</a> <a class="normal" href=" {{ url_for('.home') }}" id="currentPage">&middot flip-dial</a></li>
          <li><a href="{{ url_for('static', filename='')}}{{ cv }}" target=_blank id=" ">cv</a></li>
    		</ul>
      </nav>
  <hr id="demo">
  <div id="mainbody">
    <div id="titlebox">
      <h1>FlipDial: A Generative Model for Two-Way Visual Dialogue</h1>
      <h2>Daniela Massiceti, N. Siddharth, Puneet K. Dokania, Philip H.S. Torr</h2><br>
    </div>

    <div class="abstract">	
      We present <i>FlipDial</i>, a generative model for visual dialogue that simultaneously plays the role of both participants in a visually-grounded dialogue. Given context in
      the form of an image and an associated caption summarising the contents of the image, <i>FlipDial</i> learns both to answer questions and put forward questions, capable of
      generating entire sequences of dialogue (question-answer pairs) which are diverse and relevant to the image. To do this, <i>FlipDial</i> relies on a simple but surprisingly powerful idea: it uses
      convolutional neural networks (CNNs) to encode entire dialogues directly, implicitly capturing dialogue context, and
      conditional VAEs to learn the generative model. <i>FlipDial</i> outperforms the state-of-the-art baseline in the sequential
      answering task (1VD) on the VisDial dataset by a significant
      margin of 12 points in Mean Rank. We are the first to extend
      this paradigm to full two-way visual dialogue (2VD), where
      our model is capable of generating visually-grounded both
      questions and answers in sequence, for which we propose a
      set of novel evaluation measures and metrics.
    </div>
    <img class="abstractimg" src="{{ url_for('.static', filename='hook.svg') }}" alt=""/>

	  <hr id="tophr2">
    <nav class="navigationbar">
      <ul>
        <li><a class="normal" href=" {{ url_for('.home') }}" id="currentPage">abstract</a></li>
        <li><a class="normal" href=" {{ url_for('.onevd_demo') }}" id=" ">1vd demo</a></li>
        <li><a class="normal" href=" {{ url_for('.paper') }}" id=" ">paper</a></li>
        <li>code (coming)</li>
      </ul>
    </nav>
    <hr id="bottomhr2">

  	<div id="footerwrapper">
		  <div id="email"> daniela_at_robots.ox.ac.uk </div>
      <img src="{{ url_for('static', filename='robotgirl.png') }}" alt=""/>
	  </div>
  </div>
</div>
</body>
</html>
