<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<title>daniela massiceti // generative evaluation visdial</title>

<link href="{{url_for('static', filename='main.css')}}" rel="stylesheet" type="text/css" media="screen"/>
<link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='twitter-bootstrap.css')}}" />
<link rel="shortcut icon" href="{{ url_for('static', filename='tabby.ico')}}" >
<link rel="icon" href="{{ url_for('static', filename='tabby.ico')}}">

<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Comfortaa" />

<meta name="keywords" content="{{ mykeywords }}"/>
<meta name="description" content="daniela massiceti" />
<meta name="p:domain_verify" content="15f149f4e12ce0bf04ad541a6e0d8a62"/>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-49520497-2', 'auto');
  ga('send', 'pageview');
</script>

{% if scroll %}
<script> document.location.hash = '#' + '{{ scroll }}'; </script>
{% endif %}
</head>

<body>
<div id="wrapper">
	<header id="top">
    <a href="https://scholar.google.com/citations?user=-4fo-SwAAAAJ&hl=en" target=_blank><img id="googlescholar" src="{{ url_for('static', filename='socialmediaicons/gscholar.svg')}}" width="30" height="30" title="google scholar" alt="google scholar"/></a>
    <a href="http://za.linkedin.com/pub/daniela-massiceti/66/422/425" target=_blank><img id="linkedin" src="{{ url_for('static', filename='socialmediaicons/linkedin.png')}}" width="30" height="30" title="linkedin" alt="linkedin"/></a>
    <a href="mailto:daniela.massiceti@gmail.com" target="_top"><img id="mail" src="{{ url_for('static', filename='socialmediaicons/mail_newcolour.png')}}" width="30" height="30" title="mail: daniela.massiceti@gmail.com" alt="mail"/></a>
    <a href="https://www.twitter.com/DanniMassi/" target=_blank><img id="twitter" src="{{ url_for('static', filename='socialmediaicons/twitter.png')}}" width="30" height="30" title="twitter: @dannimassi" alt="twitter"/></a>
  </header>
   
  <div id="headerimg">
    <a href="{{ url_for('home') }}">
      <div class = "h">Daniela Massiceti</div>
    </a>
    <div class ="subh"> {{ jobtitle }} </div>
  </div>
 	<hr id="tophr"> 
	    <nav class="navigationbar" id="extendedbar">
    		<ul>
          <li><a class="normal" href="{{ url_for('home') }}" id=" ">home</a></li>
          <li><a class="normal" href="{{ url_for('about') }}" id=" ">about</a></li>
          <li><a class="normal" href="{{ url_for('research') }}" id=" ">research</a> <a class="normal" href=" {{ url_for('.home') }}" id="currentPage">&middot gen-eval-visdial</a></li>
          <li><a href="{{ url_for('static', filename='')}}{{ cv }}" target=_blank id=" ">cv</a></li>
    		</ul>
      </nav>
  <hr id="demo">
  <div id="mainbody">
    <div id="titlebox">
      <h1>A Revised Generative Evaluation of Visual Dialogue</h1>
      <h2>Daniela Massiceti, Viveka Kulharia, Puneet K. Dokania, N. Siddharth, Philip H.S. Torr</h2><br>
    </div>
    <div class="abstract">
	    Evaluating Visual Dialogue, the task of answering a sequence of questions relating to a visual input, remains an open research challenge. The current evaluation scheme of the VisDial dataset computes the ranks of ground-truth answers in predefined candidate sets, which Massiceti et al. (2018) show can be susceptible to the exploitation of dataset biases. This scheme also does little to account for the different ways of expressing the same answer--an aspect of language that has been well studied in NLP. We propose a revised evaluation scheme for the VisDial dataset leveraging metrics from the NLP literature to measure consensus between answers generated by the model and a set of relevant answers. We construct these relevant answer sets using a simple and effective semi-supervised method based on correlation, which allows us to automatically extend and scale sparse relevance annotations from humans to the entire dataset. We release these sets and code for the revised evaluation scheme as DenseVisDial, and intend them to be an improvement to the dataset in the face of its existing constraints and design choices.
    </div>
    <figure class="abstractfig" style="width: 80%">
	    <img class="abstractimg" style="margin-bottom: 15px" src="{{ url_for('.static', filename='abstracthook.png') }}" alt=""/>
	    <figcaption>We compute CIDEr (n=1 to n=4), METEOR, BERT (L2 and cosine distance), and FastText (L2 and cosine distance) scores between <i>k=1,5,10,15</i> answers generated by state-of-the-art models, and a reference set of answers for a given question. We do this for a small subset of the <i>VisDial (v1.0)</i> dataset (left) using answer reference sets annotated by humans, and the entire dataset (right) using answer reference sets automatically extracted with a semi-supervised approach.</figcaption>
    </figure>

	  <hr id="tophr2">
    <nav class="navigationbar">
      <ul>
        <li><a class="normal" href="{{ url_for('geneval_visdial.home')}}" id="currentPage">abstract</a></li>
	<li><a class="normal" href="https://arxiv.org/abs/2004.09272" target="_blank">paper</a></li>
        <li><a class="normal" href="https://github.com/danielamassiceti/geneval_visdial" target="_blank">code</a></li>
      </ul>
    </nav>
    <hr id="bottomhr2">

  	<div id="footerwrapper">
		  <div id="email"> daniela_dot_massiceti_at_gmail_dot_com </div>
      <img src="{{ url_for('static', filename='robotgirl.png') }}" alt=""/>
	  </div>
  </div>
</div>
</body>
</html>
